from langchain_community.llms import Ollama

def create_olla_llm():
    """
    This function creates an instance of Ollama LLM with specific parameters.

    Parameters:
    model (str): The model name to use for the LLM. In this case, "llama3".
    temperature (float): The temperature to use for the LLM. In this case, 0.5.

    Returns:
    Ollama: An instance of Ollama LLM with the specified parameters.
    """
    llm = Ollama(
        model="llama3",
        # temperature=0.5,
    )
    return llm

def invoke_llm(llm, prompt):
    """
    This function invokes the LLM to generate a response based on the given prompt.

    Parameters:
    llm (Ollama): The LLM instance to use for generating the response.
    prompt (str): The prompt to provide to the LLM.

    Returns:
    str: The response generated by the LLM.
    """
    res = llm.invoke(prompt)
    return res

def main():
    """
    This function demonstrates the usage of Ollama LLM by creating an instance, invoking it,
    and printing the response.
    """
    llm = create_olla_llm()
    joke = invoke_llm(llm, "Tell me a joke")
    print(joke)

if __name__ == "__main__":
    main()